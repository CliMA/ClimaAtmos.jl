<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Implicit Solver · ClimaAtmos.jl</title><meta name="title" content="Implicit Solver · ClimaAtmos.jl"/><meta property="og:title" content="Implicit Solver · ClimaAtmos.jl"/><meta property="twitter:title" content="Implicit Solver · ClimaAtmos.jl"/><meta name="description" content="Documentation for ClimaAtmos.jl."/><meta property="og:description" content="Documentation for ClimaAtmos.jl."/><meta property="twitter:description" content="Documentation for ClimaAtmos.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.svg" alt="ClimaAtmos.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">ClimaAtmos.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../contributor_guide/">Contributor Guide</a></li><li><a class="tocitem" href="../equations/">Equations</a></li><li><a class="tocitem" href="../microphysics/">Microphysics</a></li><li><a class="tocitem" href="../edmf_equations/">EDMF Equations</a></li><li><a class="tocitem" href="../diagnostics/">Diagnostics</a></li><li><a class="tocitem" href="../available_diagnostics/">Available Diagnostics</a></li><li><a class="tocitem" href="../diagnostic_edmf_equations/">Diagnostic EDMF Equations</a></li><li><a class="tocitem" href="../gravity_wave/">Gravity Wave Drag Parameterizations</a></li><li><a class="tocitem" href="../surface_albedo/">Ocean Surface Albedo Parameterization</a></li><li><a class="tocitem" href="../topography/">Topography Representation</a></li><li><a class="tocitem" href="../tracers/">Tracers</a></li><li class="is-active"><a class="tocitem" href>Implicit Solver</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Jacobian-Algorithms"><span>Jacobian Algorithms</span></a></li><li><a class="tocitem" href="#Manual-Differentiation"><span>Manual Differentiation</span></a></li><li><a class="tocitem" href="#Automatic-Differentiation"><span>Automatic Differentiation</span></a></li><li><a class="tocitem" href="#See-also"><span>See also</span></a></li></ul></li><li><a class="tocitem" href="../radiative_equilibrium/">Radiative Equilibrium</a></li><li><a class="tocitem" href="../single_column_prospect/">Single Column Model</a></li><li><a class="tocitem" href="../restarts/">Restarts and checkpoints</a></li><li><a class="tocitem" href="../repl_scripts/">REPL scripts</a></li><li><a class="tocitem" href="../config/">Configuration</a></li><li><a class="tocitem" href="../parameters/">Parameters</a></li><li><a class="tocitem" href="../longruns/">Longruns</a></li><li><a class="tocitem" href="../itime/">The time type</a></li><li><a class="tocitem" href="../api/">API</a></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Implicit Solver</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Implicit Solver</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/CliMA/ClimaAtmos.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/CliMA/ClimaAtmos.jl/blob/main/docs/src/implicit_solver.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Implicit-Solver"><a class="docs-heading-anchor" href="#Implicit-Solver">Implicit Solver</a><a id="Implicit-Solver-1"></a><a class="docs-heading-anchor-permalink" href="#Implicit-Solver" title="Permalink"></a></h1><p>The state <span>$Y$</span> is evolved using a split implicit-explicit (IMEX) timestepping scheme, which separates the tendency <span>$T(Y) = \partial Y/\partial t$</span> into implicit (fast) and explicit (slow) components,</p><p class="math-container">\[T(Y) = T_{imp}(Y) + T_{exp}(Y).\]</p><p>For an implicit step from time <span>$t$</span> to <span>$t + \Delta t$</span>, we begin with the state <span>$Y_{prev}$</span> from the explicit step at time <span>$t$</span> (which also includes information from all previous times before <span>$t$</span>), and we find a state <span>$Y$</span> that solves the implicit equation</p><p class="math-container">\[Y = Y_{prev} + \Delta t * T_{imp}(Y),\]</p><p>where <span>$\Delta t * T_{imp}(Y)$</span> is a linear approximation of the state change due to the implicit tendency between times <span>$t$</span> and <span>$t + \Delta t$</span>. Solving this equation amounts to finding a root of the residual function</p><p class="math-container">\[R(Y) = Y_{prev} + \Delta t * T_{imp}(Y) - Y,\]</p><p>since any state <span>$Y$</span> that satisfies <span>$R(Y) = 0$</span> is consistent with the linear approximation of the implicit state change.</p><p><em>Note:</em> When we use a higher-order timestepping scheme, the full step <span>$\Delta t$</span> is divided into several sub-steps or &quot;stages&quot;, where the duration of stage <span>$i$</span> is <span>$\Delta t * γ_i$</span> for some constant <span>$γ_i$</span> between 0 and 1.</p><p>To find the root of <span>$R(Y)$</span> using Newton&#39;s method, we must specify the derivative <span>$\partial R/\partial Y$</span>. Since <span>$Y_{prev}$</span> does not depend on <span>$Y$</span> (it is only a function of the state at or before time <span>$t$</span>), this derivative is given by</p><p class="math-container">\[R&#39;(Y) = \Delta t * \frac{\partial T_{imp}}{\partial Y} - I.\]</p><p>For each state <span>$Y$</span>, Newton&#39;s method computes an update <span>$\Delta Y$</span> that brings <span>$R(Y)$</span> closer to 0 by solving the linear equation</p><p class="math-container">\[R&#39;(Y) * \Delta Y = R(Y).\]</p><p><em>Note:</em> This equation comes from assuming that there is some <span>$\Delta Y$</span> for which <span>$R(Y - \Delta Y) = 0$</span> and approximating</p><p class="math-container">\[R(Y - \Delta Y) \approx R(Y) - R&#39;(Y) * \Delta Y.\]</p><p>After initializing <span>$Y$</span> to <span>$Y[0] = Y_{prev}$</span>, Newton&#39;s method executes the following steps:</p><ol><li>Compute the residual <span>$R(Y[0])$</span> and its derivative <span>$R&#39;(Y[0])$</span>.</li><li>Solve <span>$R&#39;(Y[0]) * \Delta Y[0] = R(Y[0])$</span> for <span>$\Delta Y[0]$</span>.</li><li>Update <span>$Y$</span> to <span>$Y[1] = Y[0] - \Delta Y[0]$</span>.</li></ol><p>If the number of Newton iterations is limited to 1, this new value of <span>$Y$</span> is taken to be the solution of the implicit equation. Otherwise, this sequence of steps is repeated, i.e., <span>$\Delta Y[1]$</span> is computed and <span>$Y$</span> is updated to <span>$Y[2] = Y[1] - \Delta Y[1]$</span>, then <span>$\Delta Y[2]$</span> is computed and <span>$Y$</span> is updated to <span>$Y[3] = Y[2] - \Delta Y[2]$</span>, and so on until the maximum number of iterations is reached.</p><h1 id="Jacobian-Algorithms"><a class="docs-heading-anchor" href="#Jacobian-Algorithms">Jacobian Algorithms</a><a id="Jacobian-Algorithms-1"></a><a class="docs-heading-anchor-permalink" href="#Jacobian-Algorithms" title="Permalink"></a></h1><p>The derivative <span>$\partial R/\partial Y$</span> is represented as a <a href="../api/#ClimaAtmos.Jacobian"><code>ClimaAtmos.Jacobian</code></a>, and the method for computing it and solving its linear equation is given by a <a href="../api/#ClimaAtmos.JacobianAlgorithm"><code>ClimaAtmos.JacobianAlgorithm</code></a>.</p><h2 id="Manual-Differentiation"><a class="docs-heading-anchor" href="#Manual-Differentiation">Manual Differentiation</a><a id="Manual-Differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Manual-Differentiation" title="Permalink"></a></h2><p>By making certain assumptions about the physical significance of each block in the Jacobian (see Yatunin et al., Appendix F), we can obtain a sparse matrix structure that allows for an efficient linear solver. Specifically, the time and memory required to compute the sparse matrix and the time required to run the linear solver all scale linearly with respect to the number of values in each column&#39;s state vector.</p><p>To populate the nonzero entries of this sparse matrix, the <a href="../api/#ClimaAtmos.ManualSparseJacobian"><code>ClimaAtmos.ManualSparseJacobian</code></a> specifies approximate derivatives for all possible configurations of the atmosphere model, which are analytically derived from expressions used to compute the implicit tendency. This algorithm also provides flags for zeroing out blocks of the sparse matrix, where each flag corresponds to the implicit treatment of some particular physical process.</p><h2 id="Automatic-Differentiation"><a class="docs-heading-anchor" href="#Automatic-Differentiation">Automatic Differentiation</a><a id="Automatic-Differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-Differentiation" title="Permalink"></a></h2><p>Another way to compute the Jacobian is through automatic differentiation. This involves replacing all real numbers in the prognostic state with dual numbers of the form</p><p class="math-container">\[x^D =
x + \hat{x}^1 * \varepsilon_1 + \hat{x}^2 * \varepsilon_2 + \ldots +
    \hat{x}^n * \varepsilon_n,\]</p><p>where </p><ul><li><span>$x$</span> and <span>$\hat{x}^i$</span> are real numbers, and</li><li><span>$\varepsilon_i$</span> is an infinitesimal number with the property that <span>$\varepsilon_i * \varepsilon_j = 0$</span>.</li></ul><p>Passing the dual number <span>$x + \hat{x} * \varepsilon$</span> to any function <span>$f(x)$</span> yields</p><p class="math-container">\[f(x + \hat{x} * \varepsilon) =
f(x) + \frac{\partial f(x)}{\partial x} * \hat{x} * \varepsilon.\]</p><p>By extension, passing the dual vector <span>$X + \hat{X} * \mathcal{E}$</span>, where</p><p class="math-container">\[X =
\begin{pmatrix}
    X_1 \\
    X_2 \\
    \vdots \\
    X_N
\end{pmatrix},
\mathcal{E} =
\begin{pmatrix}
    \varepsilon_1 \\
    \varepsilon_2 \\
    \vdots \\
    \varepsilon_n
\end{pmatrix},
\textrm{ and }
\hat{X} =
\begin{pmatrix}
    \hat{X}^1_1 &amp; \hat{X}^2_1 &amp; \ldots &amp; \hat{X}^n_1 \\
    \hat{X}^1_2 &amp; \hat{X}^2_2 &amp; \ldots &amp; \hat{X}^n_2 \\
    \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
    \hat{X}^1_N &amp; \hat{X}^2_N &amp; \ldots &amp; \hat{X}^n_N
\end{pmatrix},\]</p><p>to any function <span>$f(X)$</span> yields</p><p class="math-container">\[f(X + \hat{X} * \mathcal{E}) =
f(X) + \frac{\partial f(X)}{\partial X} * \hat{X} * \mathcal{E}.\]</p><p>If the dual vector is</p><p class="math-container">\[Y^D = Y + P * \mathcal{E},\]</p><p>passing it to the implicit tendency <span>$T_{imp}(Y)$</span> yields the dual tendency</p><p class="math-container">\[T_{imp}^D = T_{imp}(Y^D) =
T_{imp}(Y) + \frac{\partial T_{imp}(Y)}{\partial Y} * P * \mathcal{E},\]</p><p>so <span>$P$</span> acts as a right preconditioner for <span>$\partial T_{imp}(Y)/\partial Y$</span>. The tendency derivative can be extracted from the <span>$\varepsilon$</span> components of the dual tendency by inverting the preconditioner, after which a multiplication by <span>$\Delta t$</span> and subtraction of <span>$I$</span> gives the full Jacobian matrix <span>$\partial R(Y)/\partial Y$</span>.</p><p>To be more precise, the implicit tendency is evaluated in two function calls. The first function, <span>$p_{imp}(Y)$</span>, computes cached values that are treated implicitly, and the second function, <span>$T_{imp}(Y, p_{imp})$</span>, computes the tendency itself. Further generalizing the property of <span>$\varepsilon_i * \varepsilon_j = 0$</span> to functions of two vectors, passing <span>$A + \hat{A} * \mathcal{E}$</span> and <span>$B + \hat{B} * \mathcal{E}$</span> to any function <span>$f(A, B)$</span> yields</p><p class="math-container">\[f(A + \hat{A} * \mathcal{E}, B + \hat{B} * \mathcal{E}) =
f(A, B) +
\left(
    \frac{\partial f(A, B)}{\partial A} * \hat{A} +
    \frac{\partial f(A, B)}{\partial B} * \hat{B}
\right) * \mathcal{E}.\]</p><p>So, the dual tendency <span>$T_{imp}^D$</span> is computed in two steps, first evaluating <span>$p_{imp}(Y^D)$</span> to get</p><p class="math-container">\[p_{imp}^D =
p_{imp}(Y) + \frac{\partial p_{imp}(Y)}{\partial Y} * P * \mathcal{E},\]</p><p>and then evaluating <span>$T_{imp}(Y^D, p_{imp}^D)$</span> to get</p><p class="math-container">\[T_{imp}^D =
T_{imp}(Y, p_{imp}(Y)) +
\left(
    \frac{\partial T_{imp}(Y, p_{imp}(Y))}{\partial Y} +
    \frac{\partial T_{imp}(Y, p_{imp}(Y))}{\partial p_{imp}(Y)} *
    \frac{\partial p_{imp}(Y)}{\partial Y}
\right) * P * \mathcal{E}.\]</p><p>In other words, the single-argument tendency derivative <span>$\partial T_{imp}(Y)/\partial Y$</span> is really a shorthand for</p><p class="math-container">\[\frac{\partial T_{imp}(Y)}{\partial Y} =
\frac{\partial T_{imp}(Y, p_{imp}(Y))}{\partial Y} +
\frac{\partial T_{imp}(Y, p_{imp}(Y))}{\partial p_{imp}(Y)} *
\frac{\partial p_{imp}(Y)}{\partial Y}.\]</p><h3 id="Dense-Automatic-Differentiation"><a class="docs-heading-anchor" href="#Dense-Automatic-Differentiation">Dense Automatic Differentiation</a><a id="Dense-Automatic-Differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Dense-Automatic-Differentiation" title="Permalink"></a></h3><p>The simplest form of automatic differentiation uses a dense representation of the tendency matrix. When the number of <span>$\varepsilon$</span> components, <span>$n$</span>, is equal to the number of values in each column&#39;s state vector, <span>$N$</span>, this involves setting <span>$P$</span> to the <span>$N \times N$</span> identity matrix, so that the dual counterpart of each column&#39;s state vector is</p><p class="math-container">\[Y^D = Y + \mathcal{E} =
\begin{pmatrix}
    Y_1 + \varepsilon_1 \\
    Y_2 + \varepsilon_2 \\
    \vdots \\
    Y_N + \varepsilon_N
\end{pmatrix}.\]</p><p>Evaluating <span>$T_{imp}(Y)$</span> on this input yields the dual tendency</p><p class="math-container">\[T_{imp}^D = T_{imp}(Y) + \frac{\partial T_{imp}(Y)}{\partial Y} * \mathcal{E} =
\begin{pmatrix}
    T_{imp, 1}(Y) + \frac{\partial T_{imp, 1}(Y)}{\partial Y_1} * \varepsilon_1 +
    \frac{\partial T_{imp, 1}(Y)}{\partial Y_2} * \varepsilon_2 + \ldots +
    \frac{\partial T_{imp, 1}(Y)}{\partial Y_N} * \varepsilon_N \\
    T_{imp, 2}(Y) + \frac{\partial T_{imp, 2}(Y)}{\partial Y_1} * \varepsilon_1 +
    \frac{\partial T_{imp, 2}(Y)}{\partial Y_2} * \varepsilon_2 + \ldots +
    \frac{\partial T_{imp, 2}(Y)}{\partial Y_N} * \varepsilon_N \\
    \vdots \\
    T_{imp, N}(Y) + \frac{\partial T_{imp, N}(Y)}{\partial Y_1} * \varepsilon_1 +
    \frac{\partial T_{imp, N}(Y)}{\partial Y_2} * \varepsilon_2 + \ldots +
    \frac{\partial T_{imp, N}(Y)}{\partial Y_N} * \varepsilon_N
\end{pmatrix},\]</p><p>where the entry in the <span>$i$</span>-th row and <span>$j$</span>-th column of <span>$\partial T_{imp}(Y)/\partial Y$</span> is the coefficient of <span>$\varepsilon_j$</span> in the <span>$i$</span>-th value of <span>$T_{imp}^D$</span>.</p><p>When there are many values in each column, setting <span>$n = N$</span> can lead to excessive compilation latency, and often also poor performance. To compensate for this, the <a href="../api/#ClimaAtmos.AutoDenseJacobian"><code>ClimaAtmos.AutoDenseJacobian</code></a> splits the <span>$N$</span> values in each column&#39;s state vector into partitions of length <span>$n &lt; N$</span>, where the default value of <span>$n$</span> is 32. The partitioning is implemented by setting <span>$P$</span> to <span>$N \times n$</span> slices of the identity matrix (with the last slice possibly containing fewer than <span>$n$</span> columns), so that <span>$T_{imp}^D$</span> only contains an <span>$N \times n$</span> slice of the matrix <span>$\partial T_{imp}(Y)/\partial Y$</span>. Computing <span>$T_{imp}^D$</span> for all partitions yields the full derivative matrix.</p><p>With <span>$\partial R(Y)/\partial Y$</span> specified as a dense matrix, the time and memory required to compute it scale in proportion to <span>$N^2$</span>. The linear equation <span>$R&#39;(Y) * \Delta Y = R(Y)$</span> is solved by <a href="https://en.wikipedia.org/wiki/LU_decomposition">LU factorization</a>, where the time required to compute the L and U factors scales as <span>$N^3$</span>. After the factors are computed, the time required to invert them scales as <span>$N^2$</span>.</p><h3 id="Sparse-Automatic-Differentiation"><a class="docs-heading-anchor" href="#Sparse-Automatic-Differentiation">Sparse Automatic Differentiation</a><a id="Sparse-Automatic-Differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Sparse-Automatic-Differentiation" title="Permalink"></a></h3><p>The <code>AutoDenseJacobian</code> can be sped up by copying its entries into the <code>ManualSparseJacobian</code>. This allows the matrix to be inverted using an efficient linear solver whose runtime scales in proportion to <span>$N$</span>, rather than an LU factorization that scales as <span>$N^3$</span>. Although this improves performance on CPUs, it still results in poor runtimes compared to the sparse representation. This is especially the case on GPUs, where performance is primarily determined by memory requirements. Introducing sparsity only to avoid the factorization does not reduce the memory requirements that scale as <span>$N^2$</span>.</p><p>To make the memory requirements of automatic differentiation scale linearly with respect to <span>$N$</span>, <span>$P$</span> can be set to an <span>$N \times c$</span> column coloring matrix for the tendency derivative, so that <span>$c$</span> is the smallest value for which <span>$\partial T_{imp}(Y)/\partial Y * P$</span> is a lossless representation of the nonzero entries in <span>$\partial T_{imp}(Y)/\partial Y$</span>. Specifically, <span>$P$</span> is a binary matrix, where a 1 in row <span>$i$</span> and column <span>$j$</span> means that the tendency derivative column corresponding to <span>$Y_i$</span> is assigned color <span>$j$</span>. Ideally, <span>$P$</span> should be chosen so that no two values <span>$Y_a$</span> and<span>$Y_b$</span> can be assigned the same color if <span>$\partial T_{imp, i}(Y)/\partial Y_a$</span> and <span>$\partial T_{imp, i}(Y)/\partial Y_b$</span> are both nonzero in any row <span>$i$</span>. For any such matrix <span>$P$</span>, <span>$\partial T_{imp}(Y)/\partial Y * P$</span> uniquely represents every nonzero value in the derivative matrix, so the entries of the derivative matrix can be extracted from it without any errors.</p><p>This requirement on <span>$P$</span> can be loosened so that <span>$Y_a$</span> and <span>$Y_b$</span> can still be assigned the same color as long as <span>$\partial T_{imp, i}(Y)/\partial Y_a$</span> and <span>$\partial T_{imp, i}(Y)/\partial Y_b$</span> do not have similar magnitudes. If the derivative with respect to <span>$Y_b$</span> is negligibly small compared to the derivative with respect to <span>$Y_a$</span>, then assigning <span>$Y_b$</span> the same color as <span>$Y_a$</span> might not be an issue, since this will amount to replacing the derivative <span>$\partial T_{imp, i}(Y)/\partial Y_a$</span> in <span>$T_{imp}^D$</span> with the sum   <span>$\partial T_{imp, i}(Y)/\partial Y_a + \partial T_{imp, i}(Y)/\partial Y_b$</span>, which should be approximately equal to <span>$\partial T_{imp, i}(Y)/\partial Y_a$</span>. When the derivatives with respect to <span>$Y_a$</span> and <span>$Y_b$</span> have comparable magnitudes, though, the sum can no longer be used to approximate either of them, and the only workaround is to assign them distinct colors.</p><p>Most of the derivatives that are ignored by the<code>ManualSparseJacobian</code> are negligibly small, so they can safely be excluded from the sparsity pattern used to assign column colors. However, some of the derivatives can be ignored based on the inputs to the linear equation in which they are used, but they do not have small magnitudes. For example, derivatives with respect to <code>ρ</code> tend to be much larger than derivatives with respect to <code>ρe_tot</code>, since a adding one kilogram of air to a cubic meter will typically have a more significant effect than adding one Joule of energy. In physical simulations, though, changes of <code>δρ = 1 kg/m^3</code> tend to be much less common than changes of <code>δρe_tot = 1 J/m^3</code>. Generally, the amount by which <code>δρ</code> is smaller than <code>δρe_tot</code> exceeds the amount by which derivatives with respect to <code>ρ</code> are larger than derivatives with respect to <code>ρe_tot</code>, which means that those derivatives can be ignored when solving the linear equation.</p><p>To avoid introducing errors to <span>$\partial T_{imp}(Y)/\partial Y$</span>, the locations of all non-negligible derivatives must be included in the sparsity pattern for assigning column colors, even if those derivatives can be ignored when solving the linear equation. In many cases, this requires the introduction of additional colors, but sometimes the coloring can be extended to include these derivatives without using more colors.</p><p>The memory requirements of this algorithm scale as <span>$N * c$</span>, which can limit the range of resolutions for which the sparse representation fits in GPU memory when <span>$c$</span> is large. To avoid this, the <a href="../api/#ClimaAtmos.AutoSparseJacobian"><code>ClimaAtmos.AutoSparseJacobian</code></a> splits the <span>$c$</span> colors into partitions of length <span>$n &lt; c$</span>. Each partition sets <span>$P$</span> to an <span>$N \times n$</span> slice of the column coloring matrix, so that <span>$T_{imp}^D$</span> contains an <span>$N \times n$</span> slice of the tendency derivative&#39;s sparse representation. Computing <span>$T_{imp}^D$</span> for all partitions yields the full tendency derivative. On GPUs, the number of partitions is the smallest value for which the sparse representation fits in GPU memory (using a limit of twice the memory that is currently free); on CPUs, it is assumed that the sparse representation will always fit in memory, so only a single partition is used.</p><p>When running the <code>AutoSparseJacobian</code>, care should be taken to ensure that its entries are not polluted by non-negligible derivatives from ignored blocks (or from ignored bands within nonzero blocks). Whenever debugging reveals a difference between the nonzero values generated by sparse and dense automatic differentiation, ignored derivatives are almost always at fault. The default &quot;padding bands&quot; added to the coloring sparsity pattern should handle most non-negligible derivatives (such as the aforementioned derivatives with respect to <code>ρ</code>), but new variables and tendencies may require additional padding bands. For cases where the new padding bands that need to be added are not known in advance, the <code>AutoSparseJacobian</code> also has an option to add a fixed number of padding bands to every Jacobian block.</p><h4 id="Debugging-Sparse-Automatic-Differentiation-Errors"><a class="docs-heading-anchor" href="#Debugging-Sparse-Automatic-Differentiation-Errors">Debugging Sparse Automatic Differentiation Errors</a><a id="Debugging-Sparse-Automatic-Differentiation-Errors-1"></a><a class="docs-heading-anchor-permalink" href="#Debugging-Sparse-Automatic-Differentiation-Errors" title="Permalink"></a></h4><p>If setting <code>use_auto_jacobian = true</code> makes a simulation unstable or leads to inaccurate results, set <code>debug_jacobian = true</code> and compare the different approximations of each Jacobian block:</p><ul><li>When a block differs between two algorithms, check whether the difference is significant (i.e., whether its normalized magnitude exceeds <code>1/dt</code>).</li><li>If the <code>AutoSparseJacobian</code> and <code>ManualSparseJacobian</code> agree on a block but significantly differ from the <code>AutoDenseJacobian</code>:<ul><li>Add bands that are missing from the sparsity pattern in this block to the <code>ManualSparseJacobian</code>, which also adds them to the <code>AutoSparseJacobian</code>.</li></ul></li><li>If the <code>AutoSparseJacobian</code> and <code>AutoDenseJacobian</code> agree on a block but significantly differ from the <code>ManualSparseJacobian</code>, and if the manual approximation is more accurate than the automatic value:<ul><li>Determine which tendency term&#39;s derivative is responsible for the erroneous automatic value.</li><li>If possible, rewrite the tendency term so that it generates a more accurate derivative using dual numbers.</li><li>If this is not possible, add a new method for the tendency term that specializes on dual numbers with the tag <a href="../api/#ClimaAtmos.Jacobian"><code>ClimaAtmos.Jacobian</code></a>, overwriting the derivative automatically generated by <code>ForwardDiff.jl</code>.</li></ul></li><li>Otherwise, if the <code>AutoSparseJacobian</code> and <code>AutoDenseJacobian</code> significantly differ for a block:<ul><li>Set <code>auto_jacobian_padding_bands</code> to a large number, and check whether this discrepancy between the sparse and dense values disappears.</li><li>If padding bands do not resolve the discrepancy:<ul><li>Add non-padding bands that are missing from this block to the <code>ManualSparseJacobian</code>, which also adds them to the <code>AutoSparseJacobian</code>.</li></ul></li><li>If padding bands resolve the discrepancy:<ul><li>Find all differences between the sparsity patterns of the sparse and dense Jacobians in the same row as this block.</li><li>If any blocks (or bands within a block) are missing from this block&#39;s row of the sparse Jacobian, check whether they have unnormalized magnitudes that are significant in comparison to this block.</li><li>Extend the default padding bands of the <code>AutoSparseJacobian</code> so they cover every significant unnormalized value that could be affecting this block, and reset <code>auto_jacobian_padding_bands</code> to use the default padding bands.</li></ul></li></ul></li></ul><h2 id="See-also"><a class="docs-heading-anchor" href="#See-also">See also</a><a id="See-also-1"></a><a class="docs-heading-anchor-permalink" href="#See-also" title="Permalink"></a></h2><ul><li><a href="https://doi.org/10.22541/essoar.173940262.23304403/v1">Yatunin, D, et al., &quot;The CliMA atmosphere dynamical core: Concepts, numerics, and scaling&quot;</a>, Section 5 and Appendix F</li><li><a href="https://clima.github.io/ClimaTimeSteppers.jl/dev/algorithm_formulations/ode_solvers/">Documentation for ClimaTimeSteppers.jl</a></li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../tracers/">« Tracers</a><a class="docs-footer-nextpage" href="../radiative_equilibrium/">Radiative Equilibrium »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Wednesday 17 December 2025 01:08">Wednesday 17 December 2025</span>. Using Julia version 1.11.8.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
