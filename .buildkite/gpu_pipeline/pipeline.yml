agents:
  queue: clima
  slurm_mem: 8G
  modules: climacommon/2025_03_18 nsight-systems/2024.6.1

env:
  JULIA_MPI_HAS_CUDA: "true"
  JULIA_NVTX_CALLBACKS: gc
  JULIA_MAX_NUM_PRECOMPILE_FILES: 100
  OPENBLAS_NUM_THREADS: 1
  OMPI_MCA_opal_warn_on_missing_libcuda: 0
  SLURM_KILL_BAD_EXIT: 1
  SLURM_GRES_FLAGS: "allow-task-sharing"
  GPU_CONFIG_PATH: "config/gpu_configs/"
  MODEL_CONFIG_PATH: "config/model_configs/"
  CLIMAATMOS_GC_NSTEPS: 10

steps:
  - label: "init :GPU:"
    key: "init_gpu_env"
    command:
      - echo "--- Instantiate examples"
      - julia --project=.buildkite -e 'using Pkg; Pkg.instantiate(;verbose=true)'
      - julia --project=.buildkite -e 'using Pkg; Pkg.precompile()'
      - julia --project=.buildkite -e 'using CUDA; CUDA.precompile_runtime()'
      - julia --project=.buildkite -e 'using Pkg; Pkg.status()'
      - julia --project=.buildkite -e 'using Pkg; Pkg.add(Pkg.PackageSpec(;name="ClimaCore", rev="f2c91eed12f71cea8ef6d31e1b7069f4674753da"))'

    agents:
      slurm_gpus: 1
      slurm_cpus_per_task: 8
    env:
      JULIA_NUM_PRECOMPILE_TASKS: 8
      JULIA_MAX_NUM_PRECOMPILE_FILES: 50

  - wait

  - group: "GPU target simulations"
    steps:

      - label: "dry baroclinic wave"
        key: "baroclinic_wave_helem30"
        command:
          - mkdir -p baroclinic_wave_helem30
          - >
            nsys profile --delay 100 --trace=nvtx,mpi,cuda,osrt --output=baroclinic_wave_helem30/output_active/report
            julia --threads=3 --color=yes --project=.buildkite .buildkite/ci_driver.jl
            --config_file ${GPU_CONFIG_PATH}baroclinic_wave_helem30.yml
            --job_id baroclinic_wave_helem30
        artifact_paths: "baroclinic_wave_helem30/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
        agents:
          slurm_gpus: 1
          slurm_cpus_per_task: 4
          slurm_exclusive:

      - label: "dry baroclinic wave - 4 gpus"
        key: "baroclinic_wave_helem30_4process"
        command:
          - mkdir -p baroclinic_wave_helem30_4process
          - >
            srun --cpu-bind=threads --cpus-per-task=4
            nsys profile --delay 100 --trace=osrt,nvtx,cuda,mpi,ucx --output=baroclinic_wave_helem30_4process/output_active/report-%q{PMI_RANK}
            julia --threads=3 --color=yes --project=.buildkite .buildkite/ci_driver.jl
            --config_file ${GPU_CONFIG_PATH}baroclinic_wave_helem30.yml
            --job_id baroclinic_wave_helem30_4process
        artifact_paths: "baroclinic_wave_helem30_4process/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
          CLIMACOMMS_CONTEXT: "MPI"
        agents:
          slurm_gpus_per_task: 1
          slurm_cpus_per_task: 4
          slurm_ntasks: 4
          slurm_exclusive:
          
      - label: "moist Held-Suarez"
        key: "held_suarez_equil_helem30"
        command:
          - mkdir -p held_suarez_equil_helem30
          - >
            nsys profile --delay 100 --trace=nvtx,mpi,cuda,osrt --output=held_suarez_equil_helem30/output_active/report
            julia --threads=3 --color=yes --project=.buildkite .buildkite/ci_driver.jl
            --config_file ${GPU_CONFIG_PATH}held_suarez_equil_helem30.yml
            --job_id held_suarez_equil_helem30
        artifact_paths: "held_suarez_equil_helem30/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
        agents:
          slurm_gpus: 1
          slurm_cpus_per_task: 4
          slurm_exclusive:

      - label: "moist Held-Suarez - 4 gpus"
        key: "held_suarez_equil_helem30_4process"
        command:
          - mkdir -p held_suarez_equil_helem30_4process
          - >
            srun --cpu-bind=threads --cpus-per-task=4
            nsys profile --delay 100 --trace=nvtx,mpi,cuda,osrt --output=held_suarez_equil_helem30_4process/output_active/report-%q{PMI_RANK}
            julia --threads=3 --color=yes --project=.buildkite .buildkite/ci_driver.jl
            --config_file ${GPU_CONFIG_PATH}held_suarez_equil_helem30.yml
            --job_id held_suarez_equil_helem30_4process
        artifact_paths: "held_suarez_equil_helem30_4process/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
          CLIMACOMMS_CONTEXT: "MPI"
        agents:
          slurm_gpus_per_task: 1
          slurm_cpus_per_task: 4
          slurm_ntasks: 4
          slurm_exclusive:

  - group: "DYAMOND GPU strong scaling"
    steps:

      - label: "gpu_aquaplanet_dyamond with diagnostics - strong scaling - 1 GPU"
        command:
          - mkdir -p gpu_aquaplanet_dyamond_diag_1process
          - >
            srun --cpu-bind=threads --cpus-per-task=4
            nsys profile --delay 100 --trace=nvtx,mpi,cuda,osrt --output=gpu_aquaplanet_dyamond_diag_1process/output_active/report julia --threads=3 --color=yes --project=.buildkite .buildkite/ci_driver.jl
            --config_file ${GPU_CONFIG_PATH}gpu_aquaplanet_dyamond_diag_1process.yml
            --job_id gpu_aquaplanet_dyamond_diag_1process
        artifact_paths: "gpu_aquaplanet_dyamond_diag_1process/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
          CLIMACOMMS_CONTEXT: "MPI"
        agents:
          slurm_gpus_per_task: 1
          slurm_cpus_per_task: 4
          slurm_ntasks: 1
          slurm_mem: 32G
          slurm_time: 8:00:00
          slurm_exclusive:

      - label: "gpu_aquaplanet_dyamond - strong scaling - 1 GPU"
        command:
          - mkdir -p gpu_aquaplanet_dyamond_ss_1process
          - >
            srun --cpu-bind=threads --cpus-per-task=4
            nsys profile --delay 100 --trace=nvtx,mpi,cuda,osrt --output=gpu_aquaplanet_dyamond_ss_1process/output_active/report
            julia --threads=3 --color=yes --project=.buildkite .buildkite/ci_driver.jl
            --config_file ${GPU_CONFIG_PATH}gpu_aquaplanet_dyamond_ss.yml
            --job_id gpu_aquaplanet_dyamond_ss_1process
        artifact_paths: "gpu_aquaplanet_dyamond_ss_1process/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
          CLIMACOMMS_CONTEXT: "MPI"
        agents:
          slurm_gpus_per_task: 1
          slurm_cpus_per_task: 4
          slurm_ntasks: 1
          slurm_mem: 32G
          slurm_time: 8:00:00
          slurm_exclusive:

      - label: "gpu_aquaplanet_dyamond - strong scaling - 2 GPUs"
        command:
          - mkdir -p gpu_aquaplanet_dyamond_ss_2process
          - >
            srun --cpu-bind=threads --cpus-per-task=4
            julia --threads=3 --color=yes --project=.buildkite .buildkite/ci_driver.jl
            --config_file ${GPU_CONFIG_PATH}gpu_aquaplanet_dyamond_ss.yml
            --job_id gpu_aquaplanet_dyamond_ss_2process
        artifact_paths: "gpu_aquaplanet_dyamond_ss_2process/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
          CLIMACOMMS_CONTEXT: "MPI"
        agents:
          slurm_gpus_per_task: 1
          slurm_cpus_per_task: 4
          slurm_ntasks: 2
          slurm_mem: 32G
          slurm_time: 8:00:00
          slurm_exclusive:

      - label: "gpu_aquaplanet_dyamond - strong scaling - 4 GPUs"
        command:
          - mkdir -p gpu_aquaplanet_dyamond_ss_4process
          - >
            srun --cpu-bind=threads --cpus-per-task=4
            julia --threads=3 --color=yes --project=.buildkite .buildkite/ci_driver.jl
            --config_file ${GPU_CONFIG_PATH}gpu_aquaplanet_dyamond_ss.yml
            --job_id gpu_aquaplanet_dyamond_ss_4process
        artifact_paths: "gpu_aquaplanet_dyamond_ss_4process/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
          CLIMACOMMS_CONTEXT: "MPI"
        agents:
          slurm_gpus_per_task: 1
          slurm_cpus_per_task: 4
          slurm_ntasks: 4
          slurm_mem: 32G
          slurm_time: 8:00:00
          slurm_exclusive:

      - wait

      - label: "gpu_aquaplanet_dyamond - strong scaling plots"
        command:
          - mkdir -p gpu_aquaplanet_dyamond_ss
          - >
            julia --color=yes --project=.buildkite post_processing/plot_gpu_strong_scaling.jl gpu_aquaplanet_dyamond_ss
        artifact_paths: "gpu_aquaplanet_dyamond_ss/*"
        env:
          CLIMACOMMS_CONTEXT: "MPI"
        agents:
          slurm_cpus_per_task: 1
          slurm_ntasks: 1
          slurm_exclusive:

  - group: "DYAMOND GPU weak scaling"
    steps:

      - label: "gpu_aquaplanet_dyamond - weak scaling - 1 GPU"
        command:
          - mkdir -p gpu_aquaplanet_dyamond_ws_1process
          - >
            srun --cpu-bind=threads --cpus-per-task=4
            julia --threads=3 --color=yes --project=.buildkite .buildkite/ci_driver.jl
            --config_file ${GPU_CONFIG_PATH}gpu_aquaplanet_dyamond_ws_1process.yml
            --job_id gpu_aquaplanet_dyamond_ws_1process
        artifact_paths: "gpu_aquaplanet_dyamond_ws_1process/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
          CLIMACOMMS_CONTEXT: "MPI"
        agents:
          slurm_gpus_per_task: 1
          slurm_cpus_per_task: 4
          slurm_ntasks: 1
          slurm_mem: 32G
          slurm_time: 8:00:00
          slurm_exclusive:

      - label: "gpu_aquaplanet_dyamond - weak scaling - 2 GPUs"
        command:
          - mkdir -p gpu_aquaplanet_dyamond_ws_2process
          - >
            srun --cpu-bind=threads --cpus-per-task=4
            julia --threads=3 --color=yes --project=.buildkite .buildkite/ci_driver.jl
            --config_file ${GPU_CONFIG_PATH}gpu_aquaplanet_dyamond_ws_2process.yml
            --job_id gpu_aquaplanet_dyamond_ws_2process
        artifact_paths: "gpu_aquaplanet_dyamond_ws_2process/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
          CLIMACOMMS_CONTEXT: "MPI"
        agents:
          slurm_gpus_per_task: 1
          slurm_cpus_per_task: 4
          slurm_ntasks: 2
          slurm_mem: 32G
          slurm_time: 8:00:00
          slurm_exclusive:

      - label: "gpu_aquaplanet_dyamond - weak scaling - 4 GPUs"
        command:
          - mkdir -p gpu_aquaplanet_dyamond_ws_4process
          - >
            srun --cpu-bind=threads --cpus-per-task=4
            julia --threads=3 --color=yes --project=.buildkite .buildkite/ci_driver.jl
            --config_file ${GPU_CONFIG_PATH}gpu_aquaplanet_dyamond_ws_4process.yml
            --job_id gpu_aquaplanet_dyamond_ws_4process
        artifact_paths: "gpu_aquaplanet_dyamond_ws_4process/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
          CLIMACOMMS_CONTEXT: "MPI"
        agents:
          slurm_gpus_per_task: 1
          slurm_cpus_per_task: 4
          slurm_ntasks: 4
          slurm_mem: 32G
          slurm_time: 8:00:00
          slurm_exclusive:

      - wait

      - label: "gpu_aquaplanet_dyamond - weak scaling plots"
        command:
          - mkdir -p gpu_aquaplanet_dyamond_ws
          - >
            julia --color=yes --project=.buildkite post_processing/plot_gpu_weak_scaling.jl gpu_aquaplanet_dyamond_ws
        artifact_paths: "gpu_aquaplanet_dyamond_ws/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
          CLIMACOMMS_CONTEXT: "MPI"
        agents:
          slurm_cpus_per_task: 1
          slurm_ntasks: 1
          slurm_exclusive:



  - group: "Diagnostic EDMF GPU"
    steps:

      - label: "gpu_aquaplanet_diagedmf - 1 GPU"
        command:
          - mkdir -p gpu_aquaplanet_diagedmf
          - >
            nsys profile --delay 200 --trace=nvtx,mpi,cuda,osrt --output=gpu_aquaplanet_diagedmf/output_active/report
            julia --threads=3 --color=yes --project=.buildkite .buildkite/ci_driver.jl
            --config_file ${MODEL_CONFIG_PATH}aquaplanet_diagedmf.yml
            --job_id gpu_aquaplanet_diagedmf
        artifact_paths: "gpu_aquaplanet_diagedmf/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
          CLIMACOMMS_CONTEXT: "MPI"
        agents:
          slurm_gpus_per_task: 1
          slurm_cpus_per_task: 4
          slurm_ntasks: 1
          slurm_mem: 64G
          slurm_exclusive:

      - label: "gpu_aquaplanet_diagedmf_benchmark"
        command: >
          julia --color=yes --project=.buildkite perf/benchmark.jl
          --config_file ${MODEL_CONFIG_PATH}aquaplanet_diagedmf.yml
          --job_id gpu_aquaplanet_diagedmf_benchmark
        artifact_paths: "gpu_aquaplanet_diagedmf_benchmark/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
        agents:
          slurm_mem: 64G
          slurm_gpus: 1

  - group: "Prognostic EDMF GPU"
    steps:

      - label: "gpu_aquaplanet_progedmf - 1 GPU"
        command:
          - mkdir -p gpu_aquaplanet_progedmf
          - >
            nsys profile --delay 100 --trace=nvtx,mpi,cuda,osrt --output=gpu_aquaplanet_progedmf/output_active/report
            julia --threads=3 --color=yes --project=.buildkite .buildkite/ci_driver.jl
            --config_file ${MODEL_CONFIG_PATH}aquaplanet_progedmf.yml
            --job_id gpu_aquaplanet_progedmf
        artifact_paths: "gpu_aquaplanet_progedmf/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
          CLIMACOMMS_CONTEXT: "MPI"
        agents:
          slurm_gpus_per_task: 1
          slurm_cpus_per_task: 4
          slurm_ntasks: 1
          slurm_mem: 32G
          slurm_exclusive:

      - label: "gpu_aquaplanet_progedmf_benchmark"
        command: >
          julia --color=yes --project=.buildkite perf/benchmark.jl
          --config_file ${MODEL_CONFIG_PATH}aquaplanet_progedmf.yml
          --job_id gpu_aquaplanet_progedmf_benchmark
        artifact_paths: "gpu_aquaplanet_progedmf_benchmark/output_active/*"
        env:
          CLIMACOMMS_DEVICE: "CUDA"
        agents:
          slurm_gpus: 1
